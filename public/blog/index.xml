<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on 自由.自在</title>
    <link>/blog/</link>
    <description>Recent content in Blogs on 自由.自在</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Sep 2020 14:14:58 +0800</lastBuildDate>
    
	<atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using_tcpdump_parse_three_way_shakehand</title>
      <link>/2020/09/using_tcpdump_parse_three_way_shakehand/</link>
      <pubDate>Wed, 09 Sep 2020 14:14:58 +0800</pubDate>
      
      <guid>/2020/09/using_tcpdump_parse_three_way_shakehand/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quick_understand_network_protocl_3</title>
      <link>/2020/09/quick_understand_network_protocl_3/</link>
      <pubDate>Wed, 09 Sep 2020 11:13:51 +0800</pubDate>
      
      <guid>/2020/09/quick_understand_network_protocl_3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quick_understand_network_protocl_2</title>
      <link>/2020/09/quick_understand_network_protocl_2/</link>
      <pubDate>Wed, 09 Sep 2020 11:13:49 +0800</pubDate>
      
      <guid>/2020/09/quick_understand_network_protocl_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quick_understand_network_protocol_1</title>
      <link>/2020/09/quick_understand_network_protocol_1/</link>
      <pubDate>Wed, 09 Sep 2020 11:13:46 +0800</pubDate>
      
      <guid>/2020/09/quick_understand_network_protocol_1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Balance</title>
      <link>/2020/07/balance/</link>
      <pubDate>Wed, 15 Jul 2020 14:23:42 +0800</pubDate>
      
      <guid>/2020/07/balance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hash</title>
      <link>/2020/07/hash/</link>
      <pubDate>Wed, 15 Jul 2020 14:23:24 +0800</pubDate>
      
      <guid>/2020/07/hash/</guid>
      <description>所有的语言都会带有map这种数据结构，比如go语言叫做map，Python叫做dic，redis是使用c语言实现的内存数据库，由于c没有自带map，所以redis也有自己的字典实现。
另外有趣的是，mysql也有一种index叫做哈希索引，可见hash是一种极其常见且用途广泛的数据结构。
hash的特性  hash函数，不同输入， 经过函数的转化会得到一个摘要。 hash function不是万能的，根据场景的不同选择不同的hash function。 hash函数是有可能产生碰撞的，尤其是数据量非常大的时候 「如何解collision」？ 计算机内存不是无限的，一个可预见扩张的map，如何扩容？ 查询时间复杂度O(1), 一步查找。  hash实现 hash可以使用很多方式实现常见的有
 MD4 MD5 SHA-1 取模 CRC32  这些都是非常常见的hash函数，对于编程语言，可能会使用数组来存储key对应的value
hash冲突解决 一个设计良好的hash函数，输出比输入大，输出足够均匀，理想很饱满，现实往往做不到。
hash冲突指的是，不同的key，hash成同一个摘要。
比如
// key value pair 分别为1 a和11 b // 取模之后 hashIndex1 := 1%10 hashIndex2 := 11%10 hashIndex1 = 1 hashIndex2 = 1 // 两者相同，如果底层是数组实现的话，那么就会拿到 // key 1 和 11 都会拿到a，显然这和输入是不对应的。 为了解决hash冲突一般有两个办法，开放地址法和链表法
开放地址法 在数组中找到下一个为空的地方，将数据写入，比如上面的例子。
key 1 已经占据了数组下标为1的slot，那么11插入的时候就找下标1之后的slot是否为空，如果为空则写入key 11对应的value。
这个办法的有点是实现简单，但是一旦底层数组已经有足够多的数据，寻找空slot和获取value的时间都会变的很大。
链表法 链表法的原理是，底层数据存的是链表的head指针，链表存了真实的数据， 冲突的数据都会加载在链表的尾部，寻找数据的时候遍历链表然后比较value是否和预期一致。
rehash 对于redis而言，rehash是通过dic0和dic1来实现的，会有一个is_rehash变量。</description>
    </item>
    
    <item>
      <title>Operating system read notes</title>
      <link>/2020/07/operating-system-read-notes/</link>
      <pubDate>Sat, 11 Jul 2020 09:33:34 +0800</pubDate>
      
      <guid>/2020/07/operating-system-read-notes/</guid>
      <description>我总有很多问题，这些问题在不解决之前，总有一天他们会相遇在同一个地方，然后成为一个「大麻烦」，最近看「章老师说」，真正的SE「soft engineer」从30岁开始都算晚。所以我将读操作系统的一些要点记录下来，里面也许会回答一些我们在使用电脑过程中遇到的常见的问题。另外此书也不是一蹴而就，需要经常翻阅。notes的记录线会跟随章节来走。
基础原理 为什么要学操作系统
 as you will 「智者的故事，一只在别人背后的鸟，它的生死跟随这个人的意志转移」  现实世界的事物分为两类
 已经存在的 人造的  计算机属于人造的事物，人造的事物具有如下的特定
 不精确，具有相对性「没有绝对的好坏/对错」 从对人类活动的观察导出 「比如排队，约会等」 依赖于人的主观判断力 通常符合人的直觉  操作系统的范畴
 cpu管理 内存管理 外存管理 I/O管理  操作系统的历史 sometimes when we touch, the honest is too much. 当我们拥抱的时候，我才感受到真实，这句话非常的切合我们需要对历史的了解的必要性。
操作系统的发展历程
 sosc 「single operation single console」 单人单控制 批处理系统 多道系统 分时系统 实时系统 商业系统/个人系统/服务器系统  实际的历程比这个要复杂，这几个历程是总体是比较关键点节点，这样符合人的直觉和持续迭代的事实。比如一开始的计算机是只能一个人控制，并且由复杂的装载程序和打印程序，那个时代计算机非常的昂贵，这种资源的浪费是非常不值得，批处理系统就是可以一次性再装载完整个程序之后可以一次执行，但是人是多线程的，我们自然想计算机是否可以同时执行多个程序，这就是多道技术的出现原因，在单核时代本质上还是执行一个程序，只是感觉上执行了多个程序。但是这种方式只解决了多个程序同时执行的问题，人们有想，我是否可以多个人，在不同的时间「提前预定的时间」也能执行我自己的程序，这就是分时系统的出现「我们现在使用的多数都是分时系统」，real time系统主要是用在特定的场合，它实时的含义是，在可预测的时间之内完成计算，不然就失去了计算的意义，打个不好的比方，比如我使用滴滴打车去赶火车，如果滴滴告诉我需要30min才能到达目的地，但是这样我可能就迟到了，那我使用滴滴还有什么意义呢？ 当然假如我的预期是20min之内，那么只要有系统能做到，那么它就是我认为的实时的，这也就是说计算机的定义是相对的，不是绝对的，它的本质依然是管理有限资源的使用并且保证它们的效率和安全。
操作系统的基本概念  总线，各种设备挂载在总线上面 硬件指令流水线 指令存储单元，寄存器&amp;ndash;》缓存&amp;ndash;》内存&amp;ndash;》磁盘&amp;ndash;》磁带，执行时间1nsec&amp;mdash;》2nsec&amp;ndash;》10nsec&amp;ndash;》10msec&amp;ndash;》100sec 用户态和内核态，区分这两个态在于cpu中的状态位，内核态具有对底层资源访问的最高权限，用户态相对来说掌握的资源有限，另外用户态也可以转换成内核态，反之亦然，但是这种切换代价是很大的。 操作系统的结构，早起是网络结构，容易造成循环调用和死锁，后期发展成模块化和分层。 微内核，为了应对内核代码过多提出的概念，也就是内核的内核才放在内核态中。 进程，内存，文件 系统调用，入c语言的resutl = read(fd, buffer, nbytes), 最终会调用内核中的read函数，并且返回结果。 系统调用的参数通过压栈的方式推进，但是这也不全是，也有系统是通过寄存器来传递，如上，我们知道寄存器的速度快于内存。 没有编程语言咋办，操作系统提供一个壳，最常见的就是shell或者powershell。 系统调用如何执行，fork并且execave 进程的出现是人们对并发的渴望，进程模型也是计算机对cpu控制的体现。  进程（process）  一个程序加载到内存后就变为进程，即； 进程=程序+执行  进程模型  物理上，同一时刻，cpu只能执行一条命令，所以所有进程共用一个程序计数器 逻辑上，每个进程都觉得自己的执行，但是实际是有的进程在等待io而让出cpu控制权，所以这就需要每个进程记住自己的执行的位置，这样计数器就有多个了。 进程是程序需要分配在物理内存之上，但是资源是有限的，多个进程之间如何解决内存竞争问题？ 进程需要调度，也就是谁可以执行的问题？  进程模型的好处  提高cpu的使用效率 计算方式，假设一个程序20%的时间使用cpu，80%的时间在进行I/O，那么cpu的使用率只有20%。 1-80% = 20%。 如果是两个这样的程序呢，只有两边都在进行IO操作，cpu才被浪费，也就是 1- 80%*80% = 36%的利用率。 我们称同时执行的程序个数为度，系统cpu的利用率会随着度的提高而提高，但是后面甚至不会提高，还会下降，因为系统之间的切换将消耗大量的资源。 影响时间改善  进程的产生和消亡 产生</description>
    </item>
    
    <item>
      <title>Why MySQL Innodb engine use b&#43; tree as store of index</title>
      <link>/2020/07/why-mysql-innodb-engine-use-b-tree-as-store-of-index/</link>
      <pubDate>Mon, 06 Jul 2020 10:13:10 +0800</pubDate>
      
      <guid>/2020/07/why-mysql-innodb-engine-use-b-tree-as-store-of-index/</guid>
      <description>背景 这个问题是一个高频的面试问题，DBMS的数据库有一个要求，保持数据的持久性，那么放在内存中，由于内存掉电「断电」之后数据会丢失，且内存的价格很贵，所以mysql会选择磁盘「当然也可以不限制与此」作为数据持久化的存储方案。
优势如下 1： 容量大价格便宜，TB甚至PB级别「PB=1024tTB，TB=1024G」 2： 持久性，磁盘的数据不易丢失「物理的损坏除外」 3： 容易制造
劣势如下 1： 和内存相比读取速度较慢 2： 机械运动，稳定性不够「依赖磁臂的寻道等物理操作」
本质上内存和磁盘是没有对错之分，相对来说都是公平的，内存速度快，但是价格也很高，所以一般容量不会很大「成本无法负担」。磁盘虽然价格便宜，容量大，但是速度无法和内存「ROM/RAM」比。具体的场景下选择合适的方案，就是好的。
mysql作为关系型数据库，单表的数据量可支持到千万级别，其所产生的数据量可以达到几百G,甚至可以达到TB的级别，这些数据都存储在内存中是不现实；1：无法常驻这些数据在内存中，2：无法保证基本的特性，也就是持久性。所以选择磁盘储存是一个比较现实的方案。
当一个慢查询出来之后，我们第一时间可能是思考是不是对应字段的索引没有添加。言下之意就是，索引可以提高查询的速度，那么索引的实现，自然是一个值得讨论的问题，即为什么索引可以提高查询速度，他有什么优劣，难道是上帝的magic？
二插树「binary tree/binary search tree」 二叉树的定义是，任意左子树节点的值小于根节点，任意右子树节点的值大于根节点的值。
为什么要发明这种数据结构，是因为数组，链表都存在各自的性能问题，然后二叉树的查找，删除，插入的算法平均复杂度大概是O(logN)其中N是树的层高。
为什么说平均情况呢，因为二叉树最差的情况下会退化成链表。那么我们知道链表的查找和删除是算法复杂度是O(n), 这显然是我们不想看到的不平衡的情况， 这会造成性能的突然下降。 所以为了解决这个问题，需要引入平衡二叉树。
二叉树图1-1； 平衡二叉树「self-balancing-binary-search-tree」 AVL全称自平衡树，叫这个名字是因为，这是他发明者字母的组合（G. M. Adelson-Velsky 和 E. M. Landis）。
AVL的定义是；任何节点的两子树的最大高度差别为1「注意这里说的其实是绝对值」。其删除/增加的操作通过旋转来保持平衡，并且左右两个子树都是平衡的。
旋转分为ll，rr，lr，rl四种操作，其可以保证avl的高度平衡。但是大量平衡操作非常耗费时间。
b树 为什么要发明b树。 b树是多路平衡查找树，相对于avl或者红黑树来讲，树高更低，更加有理由磁盘的I/O, b树的每一个节点，非叶子节点和叶子节点，都存储了真实的数据，导致m阶不会太大。
b+树 b+树是b树的改进，非叶子节点存的是索引，真实的数据存在叶子节点当中，这就意味着，假设m阶= 1000，那么只需要树高为3就可以存1000000000个索引，而I/O却非常少。 并且b+树也是有序的，对于范围查找来说，可以利用局部性原理（local of reference）， 经常访问的数据可以更好的load to memory， 加快查询的速度。 总结而言，b+树是为现代磁盘而生的一种数据结构，通过压缩树的高度，获得更少的I/O, 通过索引和数据分离，存储更多的索引，更好应对大表的查询。数据通过双向链表连接在一起。
links: https://baike.baidu.com/item/AVL%E6%A0%91/10986648?fr=aladdinss</description>
    </item>
    
    <item>
      <title>Redis_distributed_lock</title>
      <link>/2020/07/redis_distributed_lock/</link>
      <pubDate>Mon, 06 Jul 2020 10:10:38 +0800</pubDate>
      
      <guid>/2020/07/redis_distributed_lock/</guid>
      <description>典型场景 如果，我们要确定一个数据存在系统中，然后才对其做更新操作，那么再并发的情况下，很容易碰到多线程交替运行情况。这是因为两个线程之间对这代码的执行不是隔离的，或者这两个操作不是原子性。 这里不要跟数据库的原子性搞搞混。单机环境下可以靠锁来解决这个问题，在分布式环境中，单机的锁失效，这个时候保证数据一致性就要依靠分布式锁来实现。
redis分布式锁 分布式锁主要使用redis的setNX command来实现。
  加锁setNX key value, 这个命令操作的是，当key不存在时，对key设置value，这个key就是业务中的锁，大概类似：XXX:ZZZ:YYY。
  业务执行完毕，释放锁，DEL key, 删除之后其他线程可以回到step 1获得锁。
  锁必须带有超时， EXPIRE key timeout，设置key的过期时间，保证DEL key失败的情况，锁可以自动释放，而不是资源被占用。
  这段代码的问题有很多，首先没有显示的释放锁，其他线程必须等待超时时间到，然后自动的释放锁，才能或得这把锁，业务才能往下执行。
redis本身的问题，获取锁和超时时间不是atomic redis现在的版本可以保证setnx这个命令是原子的，但是expire并非原子的操作，执行完setnx操作，是可以插入其他的操作，这时redis服务器可能挂掉，网络等问题。 导致这把锁如果没有显示删除的情况下，就不会自动的释放，其他线程就无法执行业务，如果是非常重要的业务，那这就是一个很大的问题。
redis提供了lua脚本，一种可以使得命令一起执行的技术，在执行lua脚本的过程当中，其他操作必须等脚本执行完，才能执行其他的命令。这就是原子性「注意不要跟数据库的acid特性中的原子混在一起」。
redis的lua脚本并不会回滚，如果setnx成功，但是expire失败, 那么lua脚本会返回错误，但是不会回滚setnx，这种情况交给业务处理。
设置了锁也设置了超时时间就万事大吉？ 下面的图可能有点极端，但是并不是不可能的事情，极端的情况下会出现线程1将线程2的锁释放，导致线程n在此刻不应该获得锁，但是获取到了锁，导致同时有两个线程对同一把锁上的业务执行操作。
举个🌰，假设图中业务是对某一个用户发送短信，那么就可能会出现对用户发送多条短信可能，因为线程2和线程n可以同时执行，因为锁被线程1显示的删除，线程2的锁没有了，其他线程可以获得锁，这是我们不愿意看到的结果。
误删除这种情况，可以通过在key上做文章
 prefix:线程标识  那么线程1在释放锁的时候，需要判断线程1的key value是否等于当前删除的key的value，显然线程1设置的value和线程2设置的value是不一样的，那么也就无法误删除线程2的锁。
锁超时自动释放？ key上的锁如果超时释放了，那么线程2就可以获得锁，两个线程就会并发执行。还是看上面这张图，显然这也是我们不愿意看到的结果。
解决的方案
 评估业务复杂度，设置合理的锁过期时间，确保业务可以执行完。 这种就比较负责了，线程2检查锁是否将要过期，如果是则主动再添加一段过期时间，太复杂了 😁  锁还没有释放，但是其他的业务也要执行？ 检查锁的操作是立即返回，如果锁存在则会通知客户端此request无效，但是对于有些业务来说，必须要等待执行怎么办？
 客户端，主动轮训 ，等待其他线程释放锁。 订阅锁释放消息 ，然后blocking住，当收到锁释放的消息之后，加锁吗，然后执行任务。  别忘记了还有集群模式 redis的高可用方案，一般采用主从模式部署，当主从同步不一致的时候，比如slave落后了master，但是master这个时候挂掉了，集群感知到了没有master，提升slave作为master。 但是好巧不巧，slave落后的消息就是线程1加锁的那条消息，那么slave就不知道已经被锁，从而其他线程可以拿到同样的锁，从而导致并发执行。
集群原地裂开「脑裂开」 当master节点和slave节点和sentinel集群处在不同的子网当中，子网突然断开联系，master节点和salve失去联系， sentinel集群从slave中找到一个节点提升为master，那么”系统“中存在两个master，客户端就有可能连接到不同的master 换句话说，不同的客户端可以拿到相同的锁，并发执行，锁失效。
总结 使用redis作为分布式锁，并发是完美的，极端情况下依然会出现并发执行的情况，这种方案可以作为一种通用的补充，比如可以忍受部分概率的并发。正在要防止并发 还是要靠数据库的防止并发手段，比如开启事务，或者是任务队列。</description>
    </item>
    
    <item>
      <title>Gof_read_notes</title>
      <link>/2020/06/gof_read_notes/</link>
      <pubDate>Thu, 11 Jun 2020 15:49:17 +0800</pubDate>
      
      <guid>/2020/06/gof_read_notes/</guid>
      <description>设计模式，是一种经验集合，这些经验和经验的实践历经了时间的考验，渐渐变成了可以开箱就用的工具，而学习这些工具的最好办法就是了解它的演变史，并且实践和掌握它的具体用法，但是设计模式不是万能的解药，但是它也是极其极其重要的。
设计原则（这一点非常重要，你可以忘记设计模式，但是别忘记【原则】  封装变化。 多用组合（composition），少用继承（extend）。 针对接口编程，不针对实现编程。 为了交互对象之间的松耦合设计而做努力。 类应该对扩展开放，对修改关闭。这一点不分语言，理论上都需要这样，好处是新功能的引入不会影响到既有的功能。具体体现就是引入bug会很少，甚至没有。 最少知识原则，只和你的密友谈话。 别找我，我会去找你。我指高级的类，你指低层级的类。 单一原则，一个类应该只有一个引起变化的原因，往往遵循此原则的类，也会高内聚。  模式的目的  可复用 可维护 可扩张  唯有这样，宝贵精力的才不会陷入无穷无尽的修改和奔波当中。
模式概述+金句解读 策略模式；
定义了算法族，分别封装起来，让它们之间可以相互替换，此模式让算法的变化独立于使用算法的客户。
策略模式人话版本；
当你需要给朋友留下深刻的印象，或者是想让你的第三个女朋友答应嫁给你，请使用这个【定义】。
观察者模式；
在对象直接定义了一对多的依赖，这样一来，当一个对象改变改变状态，依赖的状态都会收到通知并且自动更新
 观察者模式定义了对象之间一对多的关系。 被观察者（也就是subject）用一个共同的接口来更新观察者。 观察者和可观察者之间用松耦合的方式结合，可观察者不知道观察者的实现细节，只知道观察者实现了观察者接口。 使用此模式可以使用push或者pull的拉取方式，一般认识push是正确的。 如果有多个观察者，不能依赖通知的顺序。 尽量自己实现，而不是用java的内置工具。 依赖抽象，而不是具体的类。  装饰者模式； 动态的将责任附加到对象上，提供了一种区别于继承的扩张方法。 按照我的理解，装饰者模式非常的类似于组合，单不同的是，就如定义中“动态的将责任附加到对象上”，这种组合关系是非常明确的，基础对象，比如书中的例子”星巴克咖啡“，可能有m种，每种有n个装饰对象，一杯咖啡，可以有牛奶的添加，糖的添加，甚至杯子的大小，也可以装饰咖啡，所以我才说这种组合关系是明确的，并且他们都有共通的特性，比如有自己描述（”牛奶“，”可卡”，“大杯”），价格（1毛钱，5毛钱）。
这样的装饰下，对象也遵循了对扩张开放，对修改关闭。但是也不是说没有问题，装饰者对象足够下，且足够多的时候，也会给开发人员带来困恼。
并且它的具体实现；当然这里说的都是面向接口编程而不是具体的实现
d1 = new concreted1(d1) d1 = new concreted2(d1) d1 = new concreted3(d1) d1 = new concreted4(d1) d1 = new concreted5(d1) . . . 这种写法如果写多了，就要跟小学生数数一样，看看自己出错在哪里了😄 而且具体的调用过程类似递归，装饰者最终调用到被装饰者，然后再层层返回。 工厂方法模式； 定义了创建对象的接口，但是由子类决定实例化的类是哪一个。工厂方法的存在让类把实例化推迟到子类。
比如某一种指定类型的pizza店，当客户下单的时候，才会去调用工厂方法，让其返回给我一个pizza，也就是createpizza（）， 那么所有的子类就是具体的pizza，而延迟实例化，就是当需要的时候才去实例化具体的pizza。
这样做的好处是什么？ 抽象了创建pizz的过程，任何人都可以开一个pizza店，只要有需要的时候（实例化）。</description>
    </item>
    
    <item>
      <title>MySQL Isolation Level Introduction</title>
      <link>/2020/06/mysql-isolation-level-introduction/</link>
      <pubDate>Thu, 04 Jun 2020 10:23:52 +0800</pubDate>
      
      <guid>/2020/06/mysql-isolation-level-introduction/</guid>
      <description>事物的隔离级别 当对数据库的操作是并发的，多个事物互相交叉运行，可能会出现不同的事物，对同一个数据进行读写操作，极大的概率会破坏预期。mysql的innodb存储引擎提出了四种隔离级别；
 读未提交 （read uncommitted） 读提交 （read committed） 可重复读 （read repeated） 串行化 （serializable）  隔离级别定义了事物之间相互影响的关系，比如最严格的串行化，意味着两个事物对同一批数据进行操作，只能是其中一个事物执行，另外的事物“排队”等待，当前面的事物执行完毕，才能执行，这就说明了，事物之间不会存在影响， 其他的三种隔离级别都不满足严格的【事物】定义。
脏读 事物1可以读到事物2未提交的数据【脏数据】， 这个叫做脏读。
mysql&amp;gt; select * from foo; +----+-------------+------+ | id | name | year | +----+-------------+------+ | 1 | li_lei | 1991 | | 2 | han_mei_mei | 1992 | | 3 | shang_hai | 1993 | +----+-------------+------+ 不可重复读 事物1中多次读取同一条数据的结果不一致，称为不可重复读。这里和脏读会有类似的感觉，两者之间的区别是；
 脏读读到的是其他事物未提交的数据 不可重复读读到的是其他事物已经提交的数据  mysql&amp;gt; select * from foo; +----+-------------+------+ | id | name | year | +----+-------------+------+ | 1 | li_lei | 2000 | | 2 | han_mei_mei | 1992 | | 3 | shang_hai | 1993 | +----+-------------+------+ 幻读 幻读，事物1读取到的行数和之前读取到的不一致。</description>
    </item>
    
    <item>
      <title>MySQL Acid Feature</title>
      <link>/2020/06/mysql-acid-feature/</link>
      <pubDate>Wed, 03 Jun 2020 13:36:34 +0800</pubDate>
      
      <guid>/2020/06/mysql-acid-feature/</guid>
      <description>事物【transaction】 数据库事物（简称：事物）是数据库管理系统（DBMS）的一个逻辑执行单元，由一个有限的数据库操作序列构成。
数据库一般包含了一个序列的对read/write的操作，包含以下两个目的：
 为数据库操作序列提供了从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致的方法。 当多个应用程序在并发的访问数据库的时候，可以在应用程序之间提供一个隔离的办法，防止彼此的操作互干扰。  当事物提交给数据库管理系统（DBMS），DBMS需要确保事物中的所有操作都执行成功且其结果被永久的保存在数据库中，如果事物中有的操作没有完成，则事物中所有的操作都需要回滚，回到事物执行前的状态；同时，该事物对数据库或其他事物的执行无影响，所有的事物都好像独立运行。
例子：
小明使用支付宝，在淘宝上买了一件100块钱的可口可乐：
 小明的支付宝账户扣款100元 卖家余额增加100元  DBMS系统就是要确保以上两个操作【整个交易】要么一起完成，要么一起取消。否则就会出现，100元钱平白消失或者增加的情况。
在现实情况下，失败的风险很高。在一个数据库事物执行的过程中，有可能会遇上数据库事物操作失败，数据库系统/操作系统出错，甚至存储介质出错等情况。这便需要DBMS对一个操作失败的事物执行恢复操作，将其恢复到数据库一致的状态。为了实现将数据库恢复到一致状态的功能，DBMS需要维护【事物日志】以追踪事物中所有影响数据库的操作。
ACID definition  A (atomicity) 原子性，一个事物中的全部操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事物在执行过程中发生的错误，会被回滚到事物开始前的状态，就像这个事物从来都没有执行过一样。即事物不可被分割，也不可以被简约。 C (consistency) 一致性，在事物之前和事物之后，数据库的完整性没有被破坏。 I (isolation) 隔离性，数据库允许多个并发事物对数据库的读写和修改额能力，隔离性可以防止多个事物并发执行时由于交叉执行而导致数据的不一致，事物隔离分为不同的级别，read uncommitted/read committed/repeated read/serializable, 中文分别为，读未提交/读提交/可重复读/串行化。 D (durability) 持久性，事物处理结束后，对数据的修改是永久的，即使系统故障也不会丢失。  原子性: 事物日志undo log undo log,实现原子性的关键，是当事务回滚时能够撤销所有已经完成的数据库操作语句。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。
undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。
以update操作为例：当事务执行update时，其生成的undo log中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到update之前的状态。
持久性：事物日志redo log redo log也是事物日志的一种。
innodb作为MySQL的存储引擎，数据是存放在磁盘上，如果每次读写数据操作都要做磁盘I/O，那么效率将会非常低，为此innodb提供了缓存，叫做buffer pool，buffer pool中包含了磁盘数据页中的部分数据的映射，以此作为访问数据库的缓存； 当从数据库中读取数据的时候，首先会从buffer pool中查找，如果buffer pool中没有，则从磁盘读取后放入buffer pool； 当向数据库中写入数据的时候，会首先写入buffer pool，buffer pool中的数据会按照一定的策略定期写入磁盘（这一过程称为flush）。
buffer pool的引入，大大提高了读写数据库的效率，但是也带来了新的问题； 如果数据库宕机，而此时buffer pool中的数据未刷到磁盘中，就会造成数据丢失，数据库事物的持久性就无法保证。
于是，引入redo log来解决这个问题； 当数据库修改之后，除了修改buffer pool，还会将操作变更记录在redo log中，当事物提交的时候，会调用fsync将redo log刷到磁盘中，即使，数据库宕机，之后数据库重启之后，会再次读取redo log重做相关操作。redo log 采取的是【write-ahead logging】，所有对数据库的修改先写入redo log，再写入到buffer pool中，由此来保证即使数据库宕机，也能保证数据的一致性。</description>
    </item>
    
    <item>
      <title>300 Days Alone</title>
      <link>/2020/03/300-days-alone/</link>
      <pubDate>Sun, 08 Mar 2020 12:45:29 +0800</pubDate>
      
      <guid>/2020/03/300-days-alone/</guid>
      <description>it was only upon my arrival at the Geneva Airport that I realized it was over. Over there it was difficult physically but mostly psychologically and if I had to to do it again, Well I do not think I would.
In september 2008. I left Switzerland and it is comfort to spend 10 months alone in the archipelago of tonga in the middle of the Pacific Ocean to live, I brought with me a machete and my swiss knife I also had a medical kit, satellite phone, solar panel and battery to supply energy for my camera.</description>
    </item>
    
    <item>
      <title>[GO]web中间件(2)</title>
      <link>/2020/02/goweb%E4%B8%AD%E9%97%B4%E4%BB%B62/</link>
      <pubDate>Tue, 25 Feb 2020 11:48:49 +0800</pubDate>
      
      <guid>/2020/02/goweb%E4%B8%AD%E9%97%B4%E4%BB%B62/</guid>
      <description>&lt;p&gt;书接上文&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[GO]web中间件(1)</title>
      <link>/2020/02/goweb%E4%B8%AD%E9%97%B4%E4%BB%B61/</link>
      <pubDate>Tue, 25 Feb 2020 11:46:08 +0800</pubDate>
      
      <guid>/2020/02/goweb%E4%B8%AD%E9%97%B4%E4%BB%B61/</guid>
      <description>&lt;p&gt;web中间件常见的用途是一些公共方法的执行，譬如，获取用户的信息，压缩等。
在讲这些之前我们先实现一个go的web server。我们知道在go里面实现一个web服务器是相对容易的事情。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[GO]Context在golang数据库连接池中的实践</title>
      <link>/2020/02/gocontext%E5%9C%A8golang%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 24 Feb 2020 14:56:50 +0800</pubDate>
      
      <guid>/2020/02/gocontext%E5%9C%A8golang%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>&lt;p&gt;我们都知道使用ctx可以控制goroutine，比如取消goroutine树，或者给ctx设置一个超时，以便整个ctx树可以控制在预期的时间内执行完，不管【成功/失败】，另外context也内置了deadline属性，开发者可以方便的控制自己开启的goroutine情况 。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[GO] Context的golang实现</title>
      <link>/2020/02/go-context%E7%9A%84golang%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 21 Feb 2020 15:32:54 +0800</pubDate>
      
      <guid>/2020/02/go-context%E7%9A%84golang%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;p&gt;context是golang里面的标准库，在go里面到处都可以找到使用ctx的例子，网上有很多context的科普文章
其中也有比较写的比较好的，这部分我会贴在文章末尾。今天我们主要是带着大家如何从0到1实现一个ctx，有了这种实践之后
具体在go源码中的使用场景分析，我会放在下一篇blog中，并且结合&lt;a href=&#34;http://www.youmakemeday.com/parse-implementation-of-golang-database-sql-connection/&#34;&gt;golang数据库连接池实现&lt;/a&gt;一起探究其中的奥秘，确保能一举深刻的理解ctx。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[GO]golang如何实现lru缓存</title>
      <link>/2020/02/gogolang%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0lru%E7%BC%93%E5%AD%98/</link>
      <pubDate>Wed, 19 Feb 2020 14:07:36 +0800</pubDate>
      
      <guid>/2020/02/gogolang%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0lru%E7%BC%93%E5%AD%98/</guid>
      <description>&lt;p&gt;lru缓存，在当今依然非常热门的面试问题，笔者曾经面试【某蜓，音频领域的top公司】就问到了这个问题，当时回答的并不是好。那我们一起来看看如何从0-1实现一个完美的lru缓存。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[GO]golang数据库连接池的实现</title>
      <link>/2020/02/gogolang%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 17 Feb 2020 17:11:44 +0800</pubDate>
      
      <guid>/2020/02/gogolang%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;p&gt;Golang的database/sql包定义了常用的操作数据的方法，他提供了一个抽象，具体的driver依赖不同的数据库。
比如mysql驱动比较有名的&lt;a href=&#34;https://github.com/go-sql-driver/mysql&#34; title=&#34;&#34;&gt;MySql&lt;/a&gt;。
还有Sql Server使用较为广泛的库是 &lt;a href=&#34;https://github.com/denisenkom/go-mssqldb&#34; title=&#34;&#34;&gt;SqlServer&lt;/a&gt;。
使用者只需要提供DSN(data source name)或者tcp连接, open() db之后会返回一个*sql.DB对象。DB本身没有连接数据库，
只有当Query/Exec之后才会连接数据库。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>